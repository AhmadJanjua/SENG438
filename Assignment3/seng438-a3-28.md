**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group: Group Number   28  |
|-----------------|
| Student 1 name:   Ahmad Janjua        |   
| Student 2 name:   Maxwell Kepler      |   
| Student 3 name:   Christopher Luk     |   
| Student 4 name:   Matthew Ho          | 

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

**Table of Contents**

[1 Introduction	](#introduction)

[2 Manual data flow coverage calculations for X and Y methods ](#manual-data-flow-coverage-calculations-for-x-and-y-methods)

[3 A detailed description of the testing strategy for the new unit test](#a-detailed-description-of-the-testing-strategy-for-the-new-unit-test)

[4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage	](#a-high-level-description-of-five-selected-test-cases-you-have-designed-using-coverage-information-and-how-they-have-increased-code-coverage)

[5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)](#a-detailed-report-of-the-coverage-achieved-of-each-class-and-method-a-screen-shot-from-the-code-cover-results-in-green-and-red-color-would-suffice))

[6 Pros and Cons of coverage tools used and Metrics you report	](#pros-and-cons-of-coverage-tools-used-and-metrics-you-report)

[7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.](#a-comparison-on-the-advantages-and-disadvantages-of-requirements-based-test-generation-and-coverage-based-test-generation)

[8 A discussion on how the team work/effort was divided and managed](#a-discussion-on-how-the-team-workeffort-was-divided-and-managed)

[9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab](#any-difficulties-encountered-challenges-overcome-and-lessons-learned-from-performing-the-lab)

[10 Comments/feedback on the lab itself](#commentsfeedback-on-the-lab-itself)

# Introduction

In this lab, we were tasked with creating and implementing unit tests designed using white-box testing. In doing so, we learned about measuring the adequacy of our previous test suite from Lab 2 by measuring different coverage metrics. To accomplish this, we began by familiarizing ourselves with different testing tools, while trying to analyze our previous test suites on the statement, branch, and condition coverage. After this, we measured out data flow coverage manually by selecting two methods from org.jfree.data, and calculated their DU-pair coverage by tracing through their execution. We proceeded to design new unit tests to test DataUtilities and Range classes, with a goal of achieving a minimum of 90% statement coverage, 70% branch coverage, and 60% condition coverage. During this phase of the lab, we created a test plan and kept each test case in a separate method.


# Manual data-flow coverage calculations for X and Y methods

Text…

# A detailed description of the testing strategy for the new unit test

Text…

# A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

Text…

# A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

Text…

# Pros and Cons of coverage tools used and Metrics you report

Text…

# A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Text…

# A discussion on how the team work/effort was divided and managed

The success of any project is highly dependent on how well the team works together to achieve a common goal. During this lab experiment, we prioritized effective teamwork and collaboration to ensure that everyone's skills and abilities were utilized to their fullest potential. To manage the workload, we broke down the tasks into various segments and distributed them accordingly. Ahmad took on task 3.1, Max worked on task 3.2, and Matthew and Christopher collaborated on task 3.3 since Max felt most comfortable doing 3.2, and Ahmad volunteered to do 3.1. We made sure to divide the tasks as evenly as possible to ensure that no one was overburdened with work. Communication was also a crucial aspect of our team's effort. We regularly checked in with each other, shared our progress, and offered help or advice when needed. We encouraged an open and collaborative environment where everyone's thoughts and opinions were valued and respected. Moreover, we were willing to adapt and make changes to our approach as needed to ensure that we met our objectives. We were flexible in reassigning tasks or redistributing the workload to accommodate any challenges that arose during the experiment. Overall, our team effort was successful in accomplishing our goals due to effective communication, collaboration, and flexibility. We were able to leverage our individual strengths to complete the lab experiment efficiently and effectively.

# Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

During the lab experiment, we encountered some difficulties related to the compatibility between new libraries and old functions. We realized that we were only using the libraries in the assignment 3 zip folder, which was causing errors while running the tests. However, we soon discovered that we also needed the libraries in the assignment 2 folder for the tests to run without any issues. This challenge taught us the importance of being thorough and attentive to details while working on technical tasks. It also reinforced the significance of reflection and patience in the problem-solving process. Instead of getting frustrated and giving up, we took a step back and analyzed the situation to determine what was missing and how we could solve the issue. Moreover, this experience highlighted the importance of communication and collaboration in a team setting. We worked together and shared our insights to overcome the compatibility challenges and ensure that the lab experiment was completed successfully.

Another challenge that we encountered was when Christopher was creating test cases to have coverage for a conditional loop within DataUtilities and couldn’t figure out how to do it. This was an important test case to add because it improved our test suite's coverage. However, Ahmad gave him a helping hand and helped him figure out how to get the additional 1.5% line coverage. This experience showed us the significance of teamwork and support within a project. It also reinforced the importance of being resourceful and seeking help when needed. Overall, these challenges taught us valuable lessons about the importance of attention to detail, problem-solving, communication, collaboration, and support in technical projects.


# Comments/feedback on the lab itself

We found that the lab was well-structured and provided great hands-on experience in unit testing and code coverage tools. The lab's objectives were clear and focused on teaching us how to determine the adequacy of a white-box test suite based on its coverage of the code. I appreciated the emphasis on completeness, which is important when testing software to ensure it is reliable and error-free. The lab provided an excellent opportunity to learn how to use code coverage tools to measure test adequacy, design test cases, understand the benefits and drawbacks of measuring test adequacy with code coverage tools, and gain an understanding of how data-flow coverage works. Overall, the lab was a valuable learning experience that helped me deepen my understanding of unit testing and code coverage tools, and I would recommend it to other software engineering students.


