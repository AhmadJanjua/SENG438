**SENG 438- Software Testing, Reliability, and Quality**

**Lab. Report \#5 – Software Reliability Assessment**

| Group: Group Number   28  |
|-----------------|
| Student 1 name:   Ahmad Janjua        |   
| Student 2 name:   Maxwell Kepler      |   
| Student 3 name:   Christopher Luk     |   
| Student 4 name:   Matthew Ho          | 

[1 Introduction	](#introduction)

[2 Assessment Using Reliability Growth Testing ](#assessment-using-reliability-growth-testing)

[3 Assessment Using Reliability Demonstration Chart ](#assessment-using-reliability-demonstration-chart)

[4 Comparison of Results ](#comparison-of-results)

[5 Discussion on Similarity and Differences of the Two Techniques ](#discussion-on-similarity-and-differences-of-the-two-techniques)

[6 How the team work/effort was divided and managed ](#how-the-team-workeffort-was-divided-and-managed)

[7 Difficulties encountered, challenges overcome, and lessons learned ](#difficulties-encountered-challenges-overcome-and-lessons-learned)

[8 Comments/feedback on the lab itself ](#commentsfeedback-on-the-lab-itself)

# Introduction

# Assessment Using Reliability Growth Testing 

# Assessment Using Reliability Demonstration Chart 

# Comparison of Results

# Discussion on Similarity and Differences of the Two Techniques

# How the team work/effort was divided and managed

To streamline our lab work, we organized it into two different groups: part one and part two. Each section was assigned to two team members to handle. For the reliability growth testing, we split the tasks between two people. One team member used C-SFRAT to generate graphs, while the other team member analyzed the graphs and wrote detailed descriptions of the results. We followed a similar approach for the reliability demonstration chart. This strategy allowed us to efficiently complete our work while also ensuring consistency in our results.

# Difficulties encountered, challenges overcome, and lessons learned

The difficulties we faced were related to the provided software files. Specifically, SRTAT and the Reliability Demonstration Chart Excel sheet did not function as intended according to the lab handout. Further details on this issue can be found in the feedback section. Ultimately, for part one we had to resort to using C-SFRAT and for part two, we used the Reliability Demonstration Chart Excel sheet.

# Comments/feedback on the lab itself

The technical difficulties with the resources provided made this lab the most challenging one. Specifically, the SRTAT program failed to execute even after the CSV file provided in the lab artifacts was reformatted multiple times. We also tested other programs that were mentioned in the lab, but they either did not work on MAC or failed to accept the data set without heavy modification. With minimal instructions given in the lab document, navigating this issue was difficult and some team members were rendered useless. While the RDC document instructions seemed straightforward upon reading and opening the Excel sheet, the document did not function as expected. Most of the instructions were impossible to complete due to the protected view in which most of the document was displayed. Additionally, it was not possible to add data into the crucial cumulative failure count column without unprotecting the worksheet, adding to the frustration of the assignment. Overall, it’s deplorable that this assignment hasn’t been updated over the years. The challenge of the assignment shouldn’t come from a lack of concise instructions or an organized dataset, but rather from learning proper methods of analysis through clear instructions. 